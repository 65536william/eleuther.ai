---
title: GPT-Neo
date: "1635842214973"
status: Completed
cover: public/images/neo.png
category:
  - Large Language Models
tags:
  - GPT-Neo
---

[GPT-Neo](https://github.com/EleutherAI/gpt-neo) is an implementation of model & data-parallel GPT-2 and GPT-3-like models, utilizing [Mesh Tensorflow](https://github.com/tensorflow/mesh) for distributed support. This codebase is designed for TPUs. It should also work on GPUs, though we do not recommend this hardware configuration.

## Progress:

- GPT-Neo should be feature complete. We are making bugfixes, but we do not expect to make any significant changes.
- As of 31st March, 2021, 1.3B and 2.7B parameter GPT-Neo models are available to be run with [GPT-Neo](https://github.com/EleutherAI/gpt-neo).
- As of 31st March, 2021, 1.3B and 2.7B parameter GPT-Neo models are [now available on Hugging Face Model Hub](https://huggingface.co/EleutherAI)!

## Next Steps:

- We continue our efforts in in our GPU codebase, [GPT-NeoX](/projects/gpt-neox/).
