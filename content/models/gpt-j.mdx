---
title: GPT-J
date: "1635842059771"
repository: https://github.com/kingoflolz/mesh-transformer-jax/
category: Large Language Models
tags:
  - Language Modeling
---

GPT-J-6B, a 6 billion parameter model trained on the Pile, is now available for use with our new codebase, Mesh Transformer JAX.
